centos7  最小安装推荐：
yum -y install vim-enhanced tcpdump lrzsz tree telnet bash-completion net-tools wget bzip2 
lsof tmux man-pages zip unzip nfs-utils gcc make gcc-c++ glibc glibc-devel pcre pcre-devel 
openssl  openssl-devel systemd-devel zlib-devel


find / -name "*.qp" | xargs  rm -rfv  # 查找后缀 .qp 等文件并删除

常规设置：
yum provides ifconfig 或者 #可以查询到对应的软件包为 net-tools
yum whatprovides ifconfig  #可以查询到对应的软件包为 net-tools

curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
yum clean all
yum makecache

yum  install  wget  vim   ntpdate   lrzsz  bash-completion net-tools zip unzip bzip2 lsof iptables -y ipcutils

#宝塔要安装的包：
libcurl-devel wget tar zip unzip openssl openssl-devel gcc libxml2 libxml2-devel libxslt* zlib zlib-devel
 libjpeg-devel libpng-devel libwebp libwebp-devel freetype freetype-devel lsof pcre pcre-devel vixie-cron 
 crontabs icu libicu-devel c-ares libffi-devel bzip2-devel ncurses-devel sqlite-devel readline-devel tk-devel
 gdbm-devel db4-devel libpcap-devel xz-devel

#尝试同步时间(从bt.cn)
        echo 'Synchronizing system time...'
        getBtTime=$(curl -sS --connect-timeout 3 -m 60 http://www.bt.cn/api/index/get_time)
        if [ "${getBtTime}" ];then
                date -s "$(date -d @$getBtTime +"%Y-%m-%d %H:%M:%S")"
        fi

        if [ -z "${Centos8Check}" ]; then
                yum install ntp -y
                rm -rf /etc/localtime
                ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime

                #尝试同步国际时间(从ntp服务器)
                ntpdate 0.asia.pool.ntp.org
                setenforce 0
        fi
        startTime=`date +%s`
关闭 selinux
        sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config
		




yum install  vim iotop bc gcc gcc-c++ glibc glibc-devel pcre \
pcre-devel openssl  openssl-devel zip unzip zlib-devel  net-tools \
lrzsz tree ntpdate telnet lsof tcpdump wget libevent libevent-devel \
bc  systemd-devel bash-completion traceroute -y iptables

timedatectl set-timezone Asia/Shanghai
ntpdate time1.aliyun.com
yum  update
ntpdat  time1.aliyun.com  # 同步时间服务器
echo "00 */1 * * * root /usr/sbin/ntpdate time1.aliyun.com;hwclock -w" >> /etc/crontab

timedatectl  
localectl
#升级内核
rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
yum install https://www.elrepo.org/elrepo-release-8.el8.elrepo.noarch.rpm
rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-5.el7.elrepo.noarch.rpm
yum --enablerepo=elrepo-kernel  list  --showduplicates  |grep kernel*
yum --enablerepo=elrepo-kernel  list   |grep kernel*
yum --enablerepo=elrepo-kernel install -y kernel-ml kernel-ml-devel # mail 主线最新版本
yum --enablerepo=elrepo-kernel install -y kernel-lt kernel-lt-devel  #长期支持版本

rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm
yum --enablerepo=elrepo-kernel install kernel-ml

grubby  --info=ALL  # 查看grub启动信息
grubby  --default-index #查看默认启动
grubby --set-default-index 0  #设置默认启动



---------------------------------pip ------------------------------
pip  sources:
https://pypi.tuna.tsinghua.edu.cn/simple/ # 清华大学
https://mirrors.aliyun.com/pypi/simple/ # 阿里云
# 豆瓣
https://pypi.mirrors.ustc.edu.cn/simple/ # 中国科学技术大学
https://pypi.hustunique.com/ # 华中科技大学
https://mirrors.163.com/pypi/simple/      #网易
pip install -i https://pypi.douban.com/simple module # 使用豆瓣源
windows  更换source；
1.打开appdata文件夹，在资源管理器的地址栏输入%appdata%后回车
2. 新建一个pip文件夹，在pip文件夹里面新建一个配置文件pip.ini：
[global]
timeout = 6000
index-url = https://pypi.tuna.tsinghua.edu.cn/simple
trusted-host = pypi.tuna.tsinghua.edu.cn

virtualenv  -p c:\python\python38\python.exe   wk38
virtualenv  wk38
pip install -i http://pypi.douban.com/simple/ numpy   安装指定镜像源
编辑： vi ~/.pip/pip.conf
[global] 
index-url = https://pypi.tuna.tsinghua.edu.cn/simple
[install]
trusted-host = https://pypi.tuna.tsinghua.edu.cn  # 



~/.pip/pip.conf
	[global]
	index-url = https://mirrors.aliyun.com/pypi/simple/

	[install]
	trusted-host=mirrors.aliyun.com

pip  install -i  https://mirrors.aliyun.com/pypi/simple/   pika


pip  install virtualenv
virtualenv --no-site-packages venv  # 创建虚拟环境在venv 目录中， 区需要第三方软件（纯净python环境）

virtualenv  -p  d:\python39\python.exe  py39   #创建虚拟python39
virtualenv  -p  d:\python27\python.exe  py27   #创建虚拟python27
29. python
		yum  install python36
		wget  https://bootstrap.pypa.io/get-pip.py
		python get-pip.py
30  pip
		pip 加速器，
			mkdir ~/.pip
			cat > ~/.pip/pip.conf << EOF
				[global]
				trusted-host=mirrors.aliyun.com
				index-url=https://mirrors.aliyun.com/pypi/simple/
				EOF
			pip install --upgrade pip



------------------------------------------rabbit ------------------------------------
rabbitmq  3.8.14
curl -fsSL https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc | sudo apt-key add -
or
wget   https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc
apt-key add    rabbitmq-release-signing-key.asc

sudo apt-get install apt-transport-https
sudo tee /etc/apt/sources.list.d/bintray.rabbitmq.list <<EOF
## Installs the latest Erlang 23.x release.
## Change component to "erlang-22.x" to install the latest 22.x version.
## "bionic" as distribution name should work for any later Ubuntu or Debian release.
## See the release to distribution mapping table in RabbitMQ doc guides to learn more.
deb https://dl.bintray.com/rabbitmq-erlang/debian bionic erlang
## Installs latest RabbitMQ release
deb https://dl.bintray.com/rabbitmq/debian bionic main
EOF
sudo apt-get update -y
## Install rabbitmq-server and its dependencies
sudo apt-get install rabbitmq-server -y --fix-missing

rabbitmq-plugins   enable  rabbitmq-managent
rabbitmqctl  add_user wl passwd
rabbitmqctl  set_user_tags  wl administrator
http://192.168.1.96:15672  wl  pass
对wl用户设置/  权限

************************* rabbitmq- cluster ****************************************
cluster
 /etc/hosts
 
 systemctl stop rabbitmq-server
  scp /var/lib/rabbitmq/.erlang.cookie  root@ubuntu08:/var/lib/rabbitmq/
  scp /var/lib/rabbitmq/.erlang.cookie  root@ubuntu06:/var/lib/rabbitmq/
  systemctl start rabbitmq-server
  rabbitmqctl  stop_app
  rabbitmqctl   join_cluster rabbit@ubuntu06
  rabbitmqctl  start_app
  
rabbitmqctl  cluster_status
rabbitmqctl  forgot_cluster_node   rabbit@ubuntu08      # remove node  ubuntu08  

Rabbitmq服务器的主要通过rabbitmqctl和rabbimq-plugins两个工具来管理，以下是一些常用功能。

1）. 服务器启动与关闭
      启动: rabbitmq-server –detached
      关闭:rabbitmqctl stop
      若单机有多个实例，则在rabbitmqctlh后加–n 指定名称

2）. 插件管理
      开启某个插件：rabbitmq-pluginsenable xxx
      关闭某个插件：rabbitmq-pluginsdisablexxx
      注意：重启服务器后生效。
3）.virtual_host管理
      新建virtual_host: rabbitmqctladd_vhost  xxx
      撤销virtual_host:rabbitmqctl  delete_vhost xxx
4）. 用户管理
      新建用户：rabbitmqctl add_user xxx pwd
      删除用户:   rabbitmqctl delete_user xxx
      改密码: rabbimqctl change_password {username} {newpassword}
      设置用户角色：rabbitmqctl set_user_tags {username} {tag ...}
              Tag可以为 administrator,monitoring, management
5）. 权限管理
      权限设置：set_permissions [-pvhostpath] {user} {conf} {write} {read}
               Vhostpath
               Vhost路径
               user
     用户名
              Conf
      一个正则表达式match哪些配置资源能够被该用户访问。
              Write
      一个正则表达式match哪些配置资源能够被该用户读。
               Read
      一个正则表达式match哪些配置资源能够被该用户访问。
6）. 获取服务器状态信息
       服务器状态：rabbitmqctl status 
 
------------------------------------------------------------------------------ 
# 生产者

import pika
import json

credentials = pika.PlainCredentials('wl', 'pass')  # mq用户名和密码


# 虚拟队列需要指定参数 virtual_host，如果是默认的可以不填。
connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.1.96',5672,'/',credentials ))
channel=connection.channel()
# 声明消息队列，消息将在这个队列传递，如不存在，则创建
result = channel.queue_declare(queue = 'python-test')

for i in range(10):
    message=json.dumps({'OrderId':"9000%s"%i})
# 向队列插入数值 routing_key是队列名
    channel.basic_publish(exchange = '',routing_key = 'python-test',body = message)
    print(message)
connection.close()

#消费者

import pika
credentials = pika.PlainCredentials('wl', 'pass')
connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.1.96',5672,'/',credentials))
channel = connection.channel()
# 申明消息队列，消息在这个队列传递，如果不存在，则创建队列
channel.queue_declare(queue = 'python-test', durable = False)
# 定义一个回调函数来处理消息队列中的消息，这里是打印出来
def callback(ch, method, properties, body):
    ch.basic_ack(delivery_tag = method.delivery_tag)
    print(body.decode())

# 告诉rabbitmq，用callback来接收消息
channel.basic_consume(on_message_callback=callback,
                      queue = 'python-test'
                      )
channel.start_consuming()

************************************** Rabbitmq-server  8.15***********

!/bin/sh

## If sudo is not available on the system,
## uncomment the line below to install it
# apt-get install -y sudo

sudo apt-get update -y
## Install prerequisites
sudo apt-get install curl gnupg -y
## Install RabbitMQ signing key
curl -fsSL https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc | sudo apt-key add -
## Install apt HTTPS transport
sudo apt-get install apt-transport-https

## Add Bintray repositories that provision latest RabbitMQ and Erlang 23.x releases
sudo tee /etc/apt/sources.list.d/bintray.rabbitmq.list <<EOF
## Installs the latest Erlang 23.x release.
## Change component to "erlang-22.x" to install the latest 22.x version.
## "bionic" as distribution name should work for any later Ubuntu or Debian release.
## See the release to distribution mapping table in RabbitMQ doc guides to learn more.
deb https://dl.bintray.com/rabbitmq-erlang/debian groovy erlang
## Installs latest RabbitMQ release
deb https://dl.bintray.com/rabbitmq/debian groovy main
EOF

## Update package indices
sudo apt-get update -y
## Install rabbitmq-server and its dependencies
sudo apt-get install rabbitmq-server -y --fix-missing
curl -fsSL https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc | sudo apt-key add -
wget https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc 
apt-key add   rabbitmq-release-signing-key.asc
apt-get install apt-transport-https
cat  >> /etc/apt/sources.list.d/rabbitmq.list <<EOF
deb https://dl.bintray.com/rabbitmq-erlang/debian bionic erlang
deb https://dl.bintray.com/rabbitmq/debian bionic main
EOF
sudo apt-get update -y
sudo apt-get install rabbitmq-server -y --fix-missing
rabbitmq-plugins  enable rabbitmq_management  启动web 管理
cluster:
vim /etc/hosts
192.168.0.107 rabbitmq_node2
192.168.0.105 rabbitmq_node1
保证同样的配置在所有的节点上都是相同的。验证你配置的正确不正确你只需要在你的机器上ping rabbitmq_node1，试下请求的ip是不是你配置的即可。按照DNS的请求原理，hosts是最高优先权，除非浏览器有缓存，你直接用ping就不会有问题的。
选择一个节点stop，然后连接到另外节点。
rabbitmqctl stop_app
rabbitmqctl join_cluster rabbit@rabbitmq_node2
Clustering node rabbit@rabbitmq_node1 with rabbit@rabbitmq_node2 ...
rabbitmqctl start_app
systemctl stop   rabbitmq-server
scp  /var/lib/rabbitmq/.erlang.cookie  
rabbitmqctl add_user wl pass  # create a user
rabbitmqctl set_user_tags wl administrator # tag the user with "administrator" for full management UI and HTTP API access




------------------------------kafka ------------------------------------
tar zxvf  kafka_2.13-2.7.0.tgz

配置
config/server1.properties:
	broker.id=0                         # 集群不能相同
	listeners=PLAINTEXT://192.168.10.130:9092
	log.dirs=kafka-logs                      #log 目录
	zookeeper.connect=192.168.1.86:2181,192.168.1.87:2181,192.168.1.98:2181  #zookeeper  集群
	

启动服务：
//这是前台启动，启动以后，当前就无法进行其他操作（不推荐）
./zookeeper-server-start.sh ../config/zookeeper.properties
//后台启动（推荐）
./zookeeper-server-start.sh ../config/zookeeper.properties 1>/dev/null 2>&1 &
创建主题
./kafka-topics.sh --create --zookeeper localhost:2181 --config max.message.bytes=12800000 --config flush.messages=1 --replication-factor 1 --partitions 1 --topic test

命令解析：
--create： 指定创建topic动作
--topic：指定新建topic的名称
--zookeeper： 指定kafka连接zk的连接url，该值和server.properties文件中的配置项{zookeeper.connect}一样
--config：指定当前topic上有效的参数值，参数列表参考文档为: http://kafka.apache.org/082/documentation.html#brokerconfigs
--partitions：指定当前创建的kafka分区数量，默认为1个
--replication-factor：指定每个分区的复制因子个数，默认1

生产者：
./kafka-console-producer.sh --broker-list localhost:9092 --topic test
消费：
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

=========================== systemd   nginx 设置服务方式=====================================
源码编译安装nginx 实现systemd管理控制
安装nginx编译环境

yum  -y install gcc gcc-c++    openssl-devel pcre-devel gd-devel  iproute net-tools telnet wget curl
wget http://nginx.org/download/nginx-1.15.5.tar.gz
tar zxf nginx-1.15.5.tar.gz &&
cd nginx-1.15.5
./configure --prefix=/usr/local/nginx \
    --with-http_ssl_module \
    --with-http_stub_status_module 
make -j 4 && make install
通用方式启动nginx

/usr/local/nginx/sbin/nginx  #启动
/usr/local/nginx/sbin/nginx  -s reload  #重启
/usr/local/nginx/sbin/nginx -s   quit   #关闭nginx

nginx  服务：

vim      /usr/lib/systemd/system/nginx.service
[Unit]
Description=nginx
After=network.target
  
[Service]
Type=forking
ExecStart=/usr/local/nginx/sbin/nginx
ExecReload=/usr/local/nginx/sbin/nginx -s reload
ExecStop=/usr/local/nginx/sbin/nginx -s quit
PrivateTmp=true
  
[Install]
WantedBy=multi-user.target


systemctl restart nginx
systemctl enable  nginx
systemctl stop  nginx

********************** java   tomcat     ***********************************

二进制安装tomcat 实现systemd管理控制
安装java环境，我已经将安装包打包到我得服务器上，也可以去官网下载
wget  120.78.77.38/file/jdk-8u231-linux-x64.rpm
wget  120.78.77.38/file/apache-tomcat-9.0.27.tar.gz
rpm -ivh  jdk-8u231-linux-x64.rpm    #rpm直接安装jdk

配置环境变量

vim    /etc/profile
export JAVA_HOME=/usr/java/jdk1.8.0_231-amd64
export JRE_HOME=${JAVA_HOME}/jre  
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib  
export JAVA_PATH=${JAVA_HOME}/bin:${JRE_HOME}/bin
export  PATH=${JAVA_HOME}/bin:$PATH 
source   /etc/profile

java -version   #检测环境

安装tomcat
tar  -xf  apache-tomcat-9.0.27  
mv  apache-tomcat-9.0.27  /usr/local/tomcat
启动tomcat
sh    /usr/local/tomcat/bin/startup.sh   #启动
sh   /usr/local/tomcat/bin/shutdown.sh #关闭
systemd管理控制启动

vim      /usr/lib/systemd/system/tomcat.service
[Unit]
Description=tomcat server
Wants=network-online.target
After=network.target

[Service]
Type=forking
Environment="JAVA_HOME=/usr/java/jdk1.8.0_231-amd64"
Environment="PATH=$JAVA_HOME/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin"
Environment="CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar"
ExecStart=/usr/local/tomcat/bin/startup.sh
ExecStop=/usr/local/tomcat/bin/shutdown.sh
Restart=on-failure

[Install]
WantedBy=multi-user.target
systemctl restart tomcat  #启动
systemctl enable tomcat   #配置自启
systemctl stop  tomcat   #停止服务
systemctl status  tomcat  #检测状态

***************************** 部署  jar  应用 ********************************
部署jar程序 实现systemd管理控制
实际得项目中会有一些jar程序需要启动 如果手动启动则需要输入一大串命令 停止则需要杀掉进程来停止，很麻烦

举一个实际启动得例子切换到jar目录下

java -jar decode.jar -Dconfig=/usr/local/abc/application.properties
编写一个启动脚本

vim  uams.sh
#!/bin/bash
#
source /etc/profile
jarName="abc-web.jar"
workDir="/usr/local/abc"
start(){
    cd ${workDir} && java -jar ${jarName} --spring.profiles.active=prod --server.port=9630 >uams.log 2>&1 &
}
stop(){
    ps -ef | grep -qP "(?<=-jar)\s+${jarName}" && kill $(ps -ef | grep -P "(?<=-jar)\s+${jarName}" | awk '{print $2}')
}
case $1 in
    start)
        start
        ;;
    stop)
        stop
        ;;
    restart)
        stop
        start
        ;;
esac

#编写 systemd配置文件

vim      /usr/lib/systemd/system/abc.service

[Unit]
Description=uams server
Wants=network-online.target
After=network.target24 	mariadb
		yum  install  -y  mariadb  mariadb-server  
		systemctl start mariadb
		systemctl enable mariadb
		mysql_secure_installation
			首先是设置密码，会提示先输入密码
			Enter current password for root (enter for none):<–初次运行直接回车
			Set root password? [Y/n] <– 是否设置root用户密码，输入y并回车或直接回车
			New password: <– 设置root用户的密码
			Re-enter new password: <– 再输入一次你设置的密码
			Remove anonymous users? [Y/n] <– 是否删除匿名用户，回车
			Disallow root login remotely? [Y/n] <–是否禁止root远程登录,回车,
			Remove test database and access to it? [Y/n] <– 是否删除test数据库，回车
			Reload privilege tables now? [Y/n] <– 是否重新加载权限表，回车
			mysql -uroot -ppassword

25	zabbix
		安装zabbix仓库
		[root@docker-1 ~]# rpm -i https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm
		2、安装zabbix
		[root@docker-1 ~]# yum install zabbix-server-mysql zabbix-web-mysql zabbix-agent mariadb-server  -y
		3、创建zabbix数据库
		[root@docker-1 ~]# systemctl start mariadb.service
						mysql_secure_installation  安全设置向导
		[root@docker-1 ~]# mysql -uroot -p
		　　MariaDB [(none)]> create database zabbix character set utf8 collate utf8_bin;
		　　MariaDB [(none)]> grant all privileges on zabbix.* to zabbix@localhost identified by ‘11111111‘;
		　　MariaDB [(none)]> flush privileges;
		　　MariaDB [(none)]> quit;
		4、初始化数据库
		[root@docker-1 ~]# zcat /usr/share/doc/zabbix-server-mysql-4.0.0/create.sql.gz |mysql -uzabbix -p zabbix
		5、配置zabbix服务器的数据库连接密码
		[root@docker-1 ~]# vim /etc/zabbix/zabbix_server.conf
		　　DBPassword=11111111
		6、更改zabbix服务器时区
		[root@docker-1 ~]# vim /etc/httpd/conf.d/zabbix.conf
		　　php_value date.timezone Asia/Shanghai
		7、启动zabbix相关所有服务
		systemctl start httpd.service zabbix-server.service zabbix-agent.service mariadb.service
		systemctl enable httpd.service zabbix-server.service zabbix-agent.service mariadb.service
		8、web界面安装zabbix
		http://server_ip_or_name/zabbix  登陆  Admin  密码： zabbix
		9、中文乱码字体
		上传微软雅黑字体并替换DejaVuSans.ttf
			zabbix  安装 中文黑体字
			yum install wqy-microhei-fonts
			cp /usr/share/fonts/wqy-microhei/wqy-microhei.ttc  /usr/share/fonts/dejavu/DejaVuSans.ttf
		10、使用ip地址直接访问 (http DocumentRoot)
		[root@docker-1 ~]# vim /etc/httpd/conf/httpd.conf
		　　DocumentRoot "/usr/share/zabbix"
		　　systemctl restart httpd.service

	server
		rpm -i http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm
		yum install zabbix-server-mysql zabbix-web-mysql zabbix-agent
		mysql -uroot -p
			password
			mysql> create database zabbix character set utf8 collate utf8_bin;
			mysql> grant all privileges on zabbix.* to zabbix@localhost identified by 'password';
			mysql> quit
		zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix
		vim /etc/zabbix/zabbix_server.conf  设置数据库密码
		DBPassword=password
		systemctl restart zabbix-server zabbix-agent httpd
		systemctl enable zabbix-server zabbix-agent httpd
		vim /etc/httpd/conf.d/zabbix.conf, uncomment and set the right timezone for you.
			php_value date.timezone Asia/Shanghai	
		systemctl restart zabbix-server zabbix-agent httpd
		http://server_ip_or_name/zabbix 
			login:  Admin  password: zabbix
			
	client：
		1. rpm -Uvh http://repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/zabbix-release-3.2-1.el7.noarch.rpm
		2. yum  install  zabbix-agent
		3.编辑Zabbix Agent 配置文件
		vim /etc/zabbix/zabbix_agentd.conf
			Server=[zabbix server ip]
			ServerActive=[zabbix server ip]
			Hostname=[ Hostname of client system ]

		4.重启Zabbix Agent
			service zabbix-agent restart
		5.添加开机启动
			chkconfig zabbix-agent on
	设置mail 报警 通过外网邮件发送邮件
	    yum  install  postfix  
		yum  install mailx
		vim  /etc/mail.rc
			set from=wanglong@tongdelai.cn
			set smtp=stmp.yiye.163.com
			set smtp-auth-user=wanglong@tongdelai.cn
			set smtp-auth-password=sdfasdf
			set smtp-auth=login
	zabbix4.09 编译安装
		wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
		wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
		yum clean all
		yum makecache

		yum -y install gcc curl curl-devel net-snmp net-snmp-devel perl-DBI libxml2-devel libevent-devel pcre mysql-devel
		yum -y install  php php-devel  php-fpm  mariadb-server   mariadb-devel
		yum -y install php-gd php-mbstring php-bcmath php-mysql php-xml  gd-devel   php-ldap openldap  openldap-devel
		yum  -y install nginx 

		#useradd zabbix -m -s  /sbin/nologin
		groupadd --system zabbix
		useradd --system -g zabbix -d /usr/local/zabbix -s /sbin/nologin -c "Zabbix Monitoring System" zabbix

		mkdir -m u=rwx,g=rwx,o= -p /usr/local/zabbix
		chown -R  zabbix:zabbix /usr/local/zabibx

		./configure --prefix=/usr/local/zabbix/ --enable-server --with-mysql --enable-ipv6 --with-net-snmp  --with-libcurl --with-libxml2
		make && make install

		shell> mysql -uroot -p<password>
		mysql> create database zabbix character set utf8 collate utf8_bin;
		mysql> create user 'zabbix'@'localhost' identified by '<password>';
		mysql> grant all privileges on zabbix.* to 'zabbix'@'localhost';
		mysql> quit;

		shell> cd database/mysql
		cd /root/zabbix-4.0.19/database/mysql/
		shell> mysql -uzabbix -p<password> zabbix < schema.sql
		shell> mysql -uzabbix -p<password> zabbix < images.sql
		shell> mysql -uzabbix -p<password> zabbix < data.sql

		vi /etc/nginx/nginx.conf
				location / {
					root   html;
					index  index.php index.html index.htm;
				}

				location ~ \.php$ {
					root           /usr/share/nginx/html;
					fastcgi_pass   127.0.0.1:9000;
					fastcgi_index  index.php;
					fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
					include        fastcgi_params;
				}
				
		chmod -R zabbix:zabbix /usr/nginx/share/html		
		chmod 757 /usr/share/nginx/html/assets/
		nginx -t  #  检查配置文件
		ningx   启功
		nginx -s  stop    停止nginx
		nginx -s  reload   
		nginx -h               help

		\cp -a /root/zabbix-4.0.19/frontends/php/*  /usr/share/nginx/html/

		sed   -i '/post_max_size/s/8/16/g;/max_execution_time/s/30/300/g;/max_input_time/s/60/300/g;s/\;date.timezone.*/date.timezone \= PRC/g;s/\;always_populate_raw_post_data/always_populate_raw_post_data/g'  /etc/php.ini

		vi /usr/local/zabbix/etc/zabbix_server.conf
			LogFile=/tmp/zabbix_server.log
			DBHost=localhost
			DBName=zabbix
			DBUser=zabbix
			DBPassword=123456

		cp  /root/zabbix-4.0.19/misc/init.d/tru64/zabbix_server  /etc/init.d/zabbix_server
		chmod  o+x  /etc/init.d/zabbix_server
		ln -s /usr/local/zabbix/sbin/zabbix_*  /usr/local/sbin/
		/etc/init.d/zabbix_server  restart
		systemctl start mariadb
		systemctl start php-fpm
		nginx 

		Admin  zabbix
		mkdir <htdocs>/zabbix
		cd frontends/php
		cp -a . <htdocs>/zabbix

	agent:
			yum -y install gcc curl curl-devel net-snmp net-snmp-devel perl-DBI libxml2-devel libevent-devel pcre mysql-devel

			./configure --prefix=/usr/local/zabbix-agent  --enable-agent
			make && make install

			groupadd --system zabbix
			useradd --system -g zabbix -d /usr/local/zabbix -s /sbin/nologin -c "Zabbix Monitoring System" zabbix
			ln -s /usr/local/zabbix-agent/sbin/zabbix_agentd  /usr/local/sbin/zabbix_agentd
			cp /root/zabbix-4.0.19/misc/init.d/tru64/zabbix_agentd /etc/init.d/zabbix_agentd
			chmod o+x /etc/init.d/zabbix_agentd 
			[root@centos84 ~]# grep -vE '^#|^$' /usr/local/zabbix-agent/etc/zabbix_agentd.conf
				LogFile=/tmp/zabbix_agentd.log
				Server=192.168.110.87
				ServerActive=192.168.110.87
				Hostname=centos84

			/etc/init.d/zabbix_agentd start

		# rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpm
		cd  zabbix-4.0
		./configure --help    查看参数说明

			yum -y install gcc curl curl-devel net-snmp net-snmp-devel perl-DBI libxml2-devel libevent-devel pcre mysql-devel
			yum -y install gcc curl curl-devel net-snmp net-snmp-devel perl-DBI libxml2-devel libevent-devel pcre mysql-devel

		./configure --prefix=/usr/local/zabbix-agent / --enable-agent --with-mysql --enable-ipv6 --with-net-snmp  --with-libcurl --with-libxml2

		yum  install  epel-release -y
		yum  install nginx -y

		安装  php  。php-fpm
		yum install  php php-devel  php-fpm  mariadb-server   mariadb-delvel

		/etc/nginx/nginx.conf
			server {
				listen       80;
				server_name  localhost;
				#charset koi8-r;
				#access_log  logs/host.access.log  main;
				location / {
					root   /usr/share/nginx/html;
					index  index.php index.html index.htm;
				}
				#error_page  404              /404.html;
				# redirect server error pages to the static page /50x.html
				#
				error_page   500 502 503 504  /50x.html;
				location = /50x.html {
					root   html;
				location = /50x.html {
					root   html;
				}
				# proxy the PHP scripts to Apache listening on 127.0.0.1:80
				#
				#location ~ \.php$ {
				#    proxy_pass   http://127.0.0.1;
				#}
				# pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
				#
				location ~ \.php$ {
					root           /usr/share/nginx/html;
					fastcgi_pass   127.0.0.1:9000;
					fastcgi_index  index.php;
					fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
					include        fastcgi_params;
					}
				}
	
			systmctl  restart php-fpm
			yum install php-gd php-mbstring php-bcmath php-mysql php-xml  gd-devel -y
			nginx -c /etc/nginx/nginx.conf
	keepalived + nginx   高可用：
			1. nignx：
			/etc/nginx.conf
			在http 段中加入:
				upstream  web {
				server 192.168.110.81;
				server 192.168.110.82;
				}
			在server 段中加入：
			location / {
					proxy_pass http://web;
			}
			2. keepalived：
			/etc/keepalived/keepalived.conf
				master：
					vrrp_script check_nginx {
					script "/etc/keepalived/chk_nginx.sh"
					interval 1
					weight -20
					}
				vrrp_instance VI_1 {
					state MASTER
					interface ens33
					virtual_router_id 51
					priority 100
					advert_int 1
					authentication {
						auth_type PASS
						auth_pass 1111
					}
					virtual_ipaddress {
						192.168.110.99
					}
					track_script {
						check_nginx
					}
				}
				BACKUP:
					vrrp_script check_nginx {
					script "/etc/keepalived/chk_nginx.sh"
					interval 1
					weight -20
					}
				vrrp_instance VI_1 {
					state BACKUP
					interface ens33
					virtual_router_id 51
					priority 90
					advert_int 1
					authentication {
						auth_type PASS
						auth_pass 1111
					}
					virtual_ipaddress {
						192.168.110.99
					}
					track_script {
						check_nginx
					}
				}
			/etc/keepalived/chk_nginx.sh
				#!/bin/bash
				if [ `ps -C nginx --no-header  | wc -l` -eq 0 ];then 
					killall keepalived
				fi
			chmod +x /etc/keepalived/chk_nginx.sh
	-------------------------------------------------------------		
	zabbix-agent  for  mysql
        编辑 /etc/zabbix/zabbix-agentd.d/userparameter_mysql
		[root@pinzhdb zabbix_agentd.d]# pwd
		/etc/zabbix/zabbix_agentd.d
		[root@pinzhdb zabbix_agentd.d]# cat userparameter_mysql.conf
			#template_db_mysql.conf created by Zabbix for "Template DB MySQL" and Zabbix 4.2
			#For OS Linux: You need create .my.cnf in zabbix-agent home directory (/var/lib/zabbix by default) 
			#For OS Windows: You need add PATH to mysql and mysqladmin and create my.cnf in %WINDIR%\my.cnf,C:\my.cnf,BASEDIR\my.cnf https://dev.mysql.com/doc/refman/5.7/en/option-files.html
			#The file must have three strings:
			#[client]
			#user=zbx_monitor
			#password=<password>
			#
			UserParameter=mysql.ping[*],HOME=/var/lib/zabbix  /usr/local/mysql/bin/mysqladmin -h"$1" -P"$2" ping
			UserParameter=mysql.get_status_variables[*],HOME=/var/lib/zabbix /usr/local/mysql/bin/mysql -h"$1" -P"$2" -sNX -e "show global status"
			UserParameter=mysql.version[*],HOME=/var/lib/zabbix  /usr/local/mysql/bin/mysqladmin -s -h"$1" -P"$2" version
			UserParameter=mysql.db.discovery[*], HOME=/var/lib/zabbix /usr/local/mysql/bin/mysql -h"$1" -P"$2" -sN -e "show databases"
			UserParameter=mysql.dbsize[*], HOME=/var/lib/zabbix /usr/local/mysql/bin/mysql -h"$1" -P"$2" -sN -e "SELECT SUM(DATA_LENGTH + INDEX_LENGTH) FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA='$3'"
			UserParameter=mysql.replication.discovery[*],HOME=/var/lib/zabbix  /usr/local/mysql/bin/mysql -h"$1" -P"$2" -sNX -e "show slave status"
			UserParameter=mysql.slave_status[*],HOME=/var/lib/zabbix /usr/local/mysql/bin/mysql -h"$1" -P"$2" -sNX -e "show slave status"
    操作数据库建监控账户并授权:
			1.Install Zabbix agent and MySQL client.
			2.Copy template_db_mysql.conf into folder with Zabbix agent configuration (/etc/zabbix/zabbix_agentd.d/ by default). Don't forget restart zabbix-agent. 
			3.Create MySQL user for monitoring. For example:
			CREATE USER 'zbx_monitor'@'%' IDENTIFIED BY '<password>';
			GRANT USAGE,REPLICATION CLIENT,PROCESS,SHOW DATABASES,SHOW VIEW ON *.* TO 'zbx_monitor'@'%';
	在/var/lib/zabbix/下新建文件 .my.cnf
			For more information read the MYSQL documentation https://dev.mysql.com/doc/refman/8.0/en/grant.html , please. 
			4.Create .my.cnf in home directory of Zabbix agent for Linux (/var/lib/zabbix by default ) or my.cnf in c:\ for Windows. For example:
			[client]
			user='zbx_monitor'
			password='<password>'
	systemctl restart zabbix-agent
		在zabbix-server中指定模版： 
	    Template DB MySQL by Zabbix agent
	-------------------------zabbix  for nginx -------------------
    检修 ngx_status.sh 脚本， 并授权执行权限
 			[root@youzan zabbix_agentd.d]# ll
			-rw-r--r-- 1 root root  581 Mar 29 14:40 nginx.conf
			-rwxr-xr-x 1 root root 1805 Mar 29 14:18 ngx_status.sh
			[root@youzan zabbix_agentd.d]# cat ngx_status.sh 
			#!/bin/bash
			#function: monitor nginx1.16 for zabbix5.0
			#定义Nginx status页面
			ngx_status="http://127.0.0.1:8081/status"
			#判断status页面是否存活
			ngx_status_code() {
					http_code=`curl -o /dev/null -s -w %{http_code} ${ngx_status}`
					if [ ${http_code} == "200" ];then
							return 1
					else
							echo "Nginx status is not running."
					fi
			}
			#获取当前活动的客户端连接数
			active() {
					ngx_status_code || curl -s ${ngx_status} | grep "Active" | awk '{print $NF}'
			}
			#获取接收客户端连接的总数量
			accepts() {
					ngx_status_code || curl -s ${ngx_status} | awk NR==3 | awk '{print $1}'
			}
			#获取已处理的连接总数量
			handled() {
					ngx_status_code || curl -s ${ngx_status} | awk NR==3 | awk '{print $2}'
			}
			#获取客户端请求总数量
			requests() {
					ngx_status_code || curl -s ${ngx_status} | awk NR==3 | awk '{print $3}'
			}
			#获取正在读取请求标头的当前连接数量
			reading() {
					ngx_status_code || curl -s ${ngx_status} | grep "Reading" | awk '{print $2}'
			}
			#获取正在将响应写回到客户端的当前连接数量
			writing() {
					ngx_status_code || curl -s ${ngx_status} | grep "Writing" | awk '{print $2}'
			}
			#获取当前正在等待响应的客户端连接数量
			waiting() {
					ngx_status_code || curl -s ${ngx_status} | grep "Waiting" | awk '{print $2}'
			}
			#使用位置变量控制脚本输出
			case $1 in
					active)
							active;;
					accepts)
							accepts;;
					handled)
							handled;;
					requests)
							requests;;
					reading)
							reading;;
					writing)
							writing;;
					waiting)
							waiting;;
					*)
							echo "Unknown options"
			esac
		[root@youzan zabbix_agentd.d]# cat nginx.conf
			UserParameter=nginx.active,bash /etc/zabbix/zabbix_agentd.d/ngx_status.sh active
			UserParameter=nginx.accepts,bash /etc/zabbix/zabbix_agentd.d/ngx_status.sh accepts
			UserParameter=nginx.handled,bash /etc/zabbix/zabbix_agentd.d/ngx_status.sh handled
			UserParameter=nginx.requests,bash /etc/zabbix/zabbix_agentd.d/ngx_status.sh requests
			UserParameter=nginx.reading,bash /etc/zabbix/zabbix_agentd.d/ngx_status.sh reading
			UserParameter=nginx.writing,bash /etc/zabbix/zabbix_agentd.d/ngx_status.sh writing
			UserParameter=nginx.waiting,bash /etc/zabbix/zabbix_agnetd.d/ngx_status.sh waiting
		[root@youzan zabbix_agentd.d]#
      NGINX  配置文件的server 段添加配置
				location /status {
					stub_status on;
						allow 127.0.0.1;
						allow 192.168.0.71;
						allow ::1;
						deny all;
				}
        nginx -t  # 测试nginx 配置文件是否正确
		nginx -s reload  # 应用nginx新配置
		检查： curl  http://127.0.0.1:8081/status	# 显示有数据
		在zabbix-server 端测试 zabbix的监控项是否采集到数据
			zabbix-get -s  192.168.0.77 -k  nginx.active     # 显示连接数。
        在zabbix 新建模版和监控项
		在主机设置的图形界面加入新建的监控项。

25.0  prometheus
	https://prometheus.io/download/
	http://localhost:9090
	  
	默认端口  : prometheus-server: 9090; node_export:9100;windows_export:9182;mysql:9104
	server:
		tar xvfz prometheus-*.tar.gz
		cd prometheus-*	
		vi prometheus.yml：
		    static_configs:
			- targets: ['localhost:8080', 'localhost:8081']
				labels:
				group: 'production'
			- targets: ['localhost:8082']
				labels:
			 	group: 'canary'
				# Start Prometheus.
		# By default, Prometheus stores its database in ./data (flag --storage.tsdb.path).
		./prometheus --config.file=prometheus.yml
	node_export:
	    默认配置文件名称： /root/.my.cnf 
			tar -xzvf node_exporter-*.*.tar.gz
			cd node_exporter-*.*
			# Start 3 example targets in separate terminals:
			./node_exporter --web.listen-address 127.0.0.1:8080
			./node_exporter --web.listen-address :9100
 	node_mysql:
		CREATE USER 'exporter'@'%' IDENTIFIED BY 'password' WITH MAX_USER_CONNECTIONS 3;
		GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'exporter'@'%';
		export DATA_SOURCE_NAME='exporter:password@(localhost:3306)/'
		export  DATA_SOURCE_NAME='exportert:password@(localhost:3306)/db1'
		或者：
			/root/.my.cnf
				[client]
				user=root
				password=pass
				port=3306
				host=localhost
				database=db1
		cd /opt/prometheus/exporter/mysqld_exporter-0.14.0.linux-amd64
		nohup ./mysqld_exporter &

25.0.1  grafana
        git clone https://github.com/Einsteinish/Docker-Compose-Prometheus-and-Grafana.git
        访问端口：3000
		https://grafana.com/grafana/
		https://grafana.com/grafana/dashboards/    #仪表盘模版下载
		https://grafana.com/grafana/download?pg=get&plcmt=selfmanaged-box1-cta1  #下载地址
		wget https://dl.grafana.com/enterprise/release/grafana-enterprise-9.2.3-1.x86_64.rpm
		sudo yum install grafana-enterprise-9.2.3-1.x86_64.rpm
		sudo yum install initscripts urw-fonts wget
		wget <rpm package url>
		sudo rpm -Uvh <local rpm package>
		sudo yum localinstall <local rpm package>
		sudo systemctl daemon-reload
		sudo systemctl start grafana-server
		sudo systemctl status grafana-server
		sudo systemctl enable grafana-server
    IF  proxy:
			http_proxy=http://proxy.domain:3128/
			https_proxy=http://proxy.domain:3128/
			no_proxy=internal.domain,127.0.0.1
	默认配置文件：/etc/grafana/grafana.ini
	Open your web browser and go to http://localhost:3000/.



25.1   mongodb
	1.  yum.repos.d/mongodb.repo
		[mongodb-org-4.4]
		name=MongoDB Repository
		baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.4/x86_64/
		gpgcheck=1
		enabled=1
		gpgkey=https://www.mongodb.org/static/pgp/server-4.4.asc
	2.  yum  install  mongodb-org
	3.  mkdir -p /data/mongodb
	    mkdir -p /var/log/mongodb
		chown -R mongod.mongod  /data/mongodb
		chown -R mongod.mongod  /var/log/mongodb
    4.  vi /etc/mongod.conf
			path: /var/log/mongodb/mongod.log   # log path
			dbPath: /data/mongodb          # dbpath
	5.  systemctl start  mongod
	6.  ss -alnpt   #  27017  port   mongodb
	7.  mongo
	    mongodb://[username:password@]host1[:port1][,host2[:port2]  #数据库连接

26. 	JAVA 安装：
		tar  zxvf  jdkxxx.tar.gz
		mv  jdkxxx  /usr/local/java
		ln -s  /usr/local/jdkxxx /usr/local/java
			
		profile.d]# vim /etc/profile.d/java.sh
					JAVA_HOME=/usr/local/java
					CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar 
					PATH=$JAVA_HOME/bin:$HOME/bin:$HOME/.local/bin:$PATH
		source  /etc/profile.d/java.sh
		java -version  -检查java 运行正常。
		
27. 	tomcat  安装
		tar  zxvf  apach-tomcat.tar.gz
		mv  apach-tomcat /usr/local
		ln -s  apach-tomcat tomcat
		vim /etc/profile.d/tomcat.sh
			export JAVA_HOME=/usr/local/java
			export JAVA_BIN=$JAVA_HOME/bin
			export PATH=$PATH:$JAVA_HOME/bin
			export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
			export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
        source  /etc/profile.d/tomcat.sh
		/usr/local/tomcat/bin/startup.sh  -启动tomcat
	yum 安装  tomcat			
		yum install  java
		yum  install tomcat
			systemctl  start tomcat
		安装管理包
			yum install tomcat-webapps tomcat-admin-webapps 
		安装文档软件包。
			yum install tomcat-docs-webapp tomcat-javadoc

28. vsftp:
		yum install wget
		wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
		yum  install rpel-release
		yum install vsftpd db4-utils

		useradd vsftpd -M -s /sbin/nologin #建立Vsftpd服务的宿主用户
		useradd ftpvload -M -s /sbin/nologin 	#建立Vsftpd虚拟宿主用户
		修改vsftpd.conf配置文件
		主要是下面的一些配置：

			anonymous_enable=NO  #设定不允许匿名访问
			local_enable=YES  #设定本地用户可以访问。注意：主要是为虚拟宿主用户，如果该项目设定为NO那么所有虚拟用户将无法访问。
			write_enable=YES  #设定可以进行写操作。
			local_umask=022  #设定上传后文件的权限掩码。
			anon_upload_enable=NO  #禁止匿名用户上传。
			anon_mkdir_write_enable=NO  #禁止匿名用户建立目录。
			dirmessage_enable=YES  #设定开启目录标语功能。
			xferlog_enable=YES  #设定开启日志记录功能。
			connect_from_port_20=YES  #设定端口20进行数据连接。
			chown_uploads=NO  #设定禁止上传文件更改宿主。
			xferlog_file=/var/log/vsftpd.log . #设定Vsftpd的服务日志保存路径。注意，该文件默认不存在。必须要手动touch出来，并且由于这里更改了Vsftpd的服务宿主用户为手动建立的Vsftpd。必须注意给与该用户对日志的写入权限，否则服务将启动失败。
			xferlog_std_format=YES  #设定日志使用标准的记录格式。
			async_abor_enable=YES  #设定支持异步传输功能。
			ascii_upload_enable=YES 
			ascii_download_enable=YES  #设定支持ASCII模式的上传和下载功能。
			ftpd_banner=This Vsftp server supports virtual users ^_^  #设定Vsftpd的登陆标语。
			chroot_list_enable=NO  #禁止用户登出自己的FTP主目录。
			ls_recurse_enable=NO  #禁止用户登陆FTP后使用"ls -R"的命令。该命令会对服务器性能造成巨大开销。如果该项被允许，那么当多用户同时使用该命令时将会对该服务器造成威胁。
			listen=YES  #设定该Vsftpd服务工作在StandAlone模式下。
			pam_service_name=vsftpd #设定PAM服务下Vsftpd的验证配置文件名。因此，PAM验证将参考/etc/pam.d/下的vsftpd文件配置。
			userlist_enable=YES  #设定userlist_file中的用户将不得使用FTP。
			tcp_wrappers=YES  #设定支持TCP Wrappers
			#以下这些是关于Vsftpd虚拟用户支持的重要配置项目。默认Vsftpd.conf中不包含这些设定项目，需要自己手动添加配置
			guest_enable=YES  #设定启用虚拟用户功能。
			guest_username=ftpvload  #指定虚拟用户的宿主用户。
			virtual_use_local_privs=YES  #设定虚拟用户的权限符合他们的宿主用户。
			user_config_dir=/etc/vsftpd/vconf #设定虚拟用户个人Vsftp的配置文件存放路径。也就是说，这个被指定的目录里，
										将存放每个Vsftp虚拟用户个性的配置文件，一个需要注意的地方就是这些配置文件名必须和虚拟用户名相同。
			reverse_lookup_enable=NO #禁止反向域名解析，若是没有添加这个参数可能会出现用户登陆较慢，或则客户链接不上ftp的现象
			allow_writeable_chroot=YES
			use_localtime=YES 
			chroot_local_user=YES 
			pasv_enable=YES
		pasv_max_port=1500 开启随机最大的端口号
		pasv_min_port=1000 开启最小端口号
 

			mkdir /etc/vsftpd/vconf/ -pv  #制作虚拟用户数据库文件
			touch /etc/vsftpd/virtusers #新建一个测试用虚拟用户
			vim /etc/vsftpd/virtusers #编辑这个虚拟用户名单文件，在其中加入用户的用户名和口令信息。格式很简单：“奇数行用户名，偶数行口令”。
				virtusers文件格式如下：
			test #用户名
			test1234 #用户密码
			db_load -T -t hash -f /etc/vsftpd/virtusers /etc/vsftpd/virtusers.db 生成虚拟用户数据文件：
			cp /etc/pam.d/vsftpd /etc/pam.d/vsftpd.backup 编辑Vsftpd的PAM验证配置文件，把原来的配置文件全部注释掉（不注释掉虚拟用户会登录不上），添加如下行
			#vim /etc/pam.d/vsftpd
			auth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vusers
			account sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vusers
			vi /etc/vsftpd/vconf/user1
			local_root=/opt/vsftp/file
			#指定虚拟用户仓库的具路径
			anonymous_enable=NO
			#设定不允许匿名访问
			write_enable=YES
			#允许写的操作
			local_umask=022
			#上传文件的权限掩码
			anon_upload_enable=NO
			#不允许匿名上传
			anon_mkdir_write_enable=NO
			#不允许匿名用户建立目录
			idle_session_timeout=300
			#设定空闲链接超时时间
			data_connection_timeout=1000
			#设定单次传输最大时间
			max_clients=0
			#设定并发客户端的访问数量
			max_per_ip=0
			#设定客户端的最大线程数
			local_max_rate=0
			#设定用户的最大传输速率，单位b/s
		
	查看selinux 设置上传
		getsebool -a | grep ftpd
		setsebool allow_ftpd_full_access on  #  selinux 

		-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT（允许21端口通过防火墙）
		-A INPUT -m state --state NEW -m tcp -p tcp --dport 20 -j ACCEPT（允许20端口通过防火墙）
		-A INPUT -m state --state NEW -m tcp -p tcp --dport 000:9045 -j ACCEPT（设置ftp被动模式的端口范围)

		iptables -F
		iptables -A INPUT -i lo -j ACCEPT
		iptables -A INPUT -m state --state ESTABLISHED -j ACCEPT
		iptables -A OUTPUT -m state --state ESTABLISHED -j ACCEPT
		iptables -A INPUT -s 192.168.1.54 -p tcp --dport 22 -m state --state NEW -m connlimit ! --connlimit-above 3 -j ACCEPT  # ssh

		iptables -P INPUT DROP
		iptables -P OUTPUT DROP
		iptables -A INPUT -d 192.168.0.176 -p tcp --dport 21 -m state --state NEW -j ACCEPT
		iptables -A INPUT -m state --state RELATED -j ACCEPT
		iptables -A OUTPUT -m state --state RELATED -j ACCEPT
		-A INPUT -m state --state NEW -m tcp -p tcp --dport 20:21 -j ACCEPT
		iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 30000:30999 -j ACCEPT

		iptables -nvL
29. ELK
ELK +　　kafka
           filebeat -> kafka ->logstash-> elasticsearch  -> kabana
   -------------------------------filebeat ------------------
		rpm -ivh filebeat
		vi /etc/filebeat/filebeat.yml
		filebeat.inputs:
		- type: log
		enabled: true
		paths:
			- /var/log/httpd/access_log
		output.kafka:
			enable: true
			hosts: ["192.168.110.87:9092"]
			topic:  "test"
			
		systemctl start  filebeat 
		/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml


    ---------------------------------filebeat------------------
		filebeat.prospectors:
		- type: log
		enabled: true
		paths:
			- /usr/local/nginx/logs/access_json.log
		json.message_key: log
		json.keys_under_root: true
		json.overwrite_keys: true
		exclude_lines: ['^DBG',"^$"]
		document_type: access-log
		filebeat.config.modules:
		path: ${path.config}/modules.d/*.yml
		reload.enabled: false
		setup.template.settings:
		index.number_of_shards: 3
		setup.kibana:
		output.kafka:
		hosts: ["192.168.6.71:9092","192.168.6.72:9092","192.168.6.73:9092"]
		topic: elk-nginx
		required_acks: 1

    ---------------------------------------logstash-------------------
			filebeat ->logstash -> kafka->logstash->elasticsearch->kibana
			input {
				beat {
					port => 5044
					codec => json     # 直接将filebeat保存在message中的json字串解析出来
				}
			}
			filter {
				mutate {
					remove_field => ["tags", "beat"]    
					#删除filebeat自动添加的字段
					## 测试发现：如果换成drop {  remove_field =>
					## 无输出
				}
			}
			output {
				stdout {
					codec => rubydebug
				}
			}
--------------
		input {
			beats {
				port => 5044
				}
		}

		output {
			kafka {
				bootstrap_servers => "192.168.11.12:9092,192.168.11.13:9092"
				topic_id => "ecplogs"
				}
		}

		/usr/local/logstash/bin/logstash -f logstash.conf --configtest --verbose
		tar zxvf  logstash
		vi /etc/logstash/logstash.conf
		input {
				kafka{
						bootstrap_servers => "192.168.110.87:9092"
						topics => ["test"]
		}
		}

		filter {
			grok {
			match => { "message" => "%{COMBINEDAPACHELOG}" }
			}
		}

		output {
		elasticsearch {
		hosts => ["http://192.168.110.87:9200"]
		index => "logstash-%{[@metadata][version]}-%{+YYYY.MM.dd}"
		}
		# stdout {
		#  codec => rubydebug { }
		}
		}

		/usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf

     ---------------kafka --------------------------------------
		tar   zxvf  kafka
		vi kafka/config/zookeeper.properties
		dataDir=/usr/share/zookeeper/data
		server.1 = 192.168.1.2:2888:3888
		server.2= 192.168.1.3:2888:3888
		echo 1 > /usr/share/zookeeeper/data/myid
		/usr/share/kafka/bin/zookeeper-server-start.sh /usr/share/kafka/config/zookeeper.properties

		nohup bin/zookeeper-server-start.sh config/zookeeper-2.properties >>/dev/null 2>&1 &

		vi kafka/config/server.properties
		broker.id=0
		log.dirs=/usr/share/kafka/data
		zookeeper.connect=192.168.1.2:2181,192.168.1.3:2181,192.168.1.3:2181
		/usr/share/kafka/bin/kafka-server-start.sh /usr/share/kafka/config/server.properties
	测试：
		(1)建立一个主题
			[ root @ kafka1 ~ ] # /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic summer
			#注意：factor大小不能超过broker数
		(2)查看有哪些主题已经创建
			[ root @ kafka1 ~ ] # /usr/local/kafka/bin/kafka-topics.sh --list --zookeeper 192.168.2.22:2181   #列出集群中所有的topic
			bin/kafka-topics.sh --list --zookeeper localhost:2181
			summer    #已经创建成功
		(3)查看summer这个主题的详情
			[ root @ kafka1 ~ ] # /usr/local/kafka/bin/kafka-topics.sh --describe --zookeeper 192.168.2.22:2181 --topic summer
			Topic : summer PartitionCount : 1 ReplicationFactor : 3 Configs :
			Topic : summer Partition : 0 Leader : 2 Replicas : 2 , 4 , 3 Isr : 2 , 4 , 3
			#主题名称：summer
			#Partition:只有一个，从0开始
			#leader ：id为2的broker
			#Replicas 副本存在于broker id为2,3,4的上面
			#Isr:活跃状态的broker
		(4)发送消息，这里使用的是生产者角色
			bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
			[ root @ kafka1 ~ ] # /bin/bash /usr/local/kafka/bin/kafka-console-producer.sh --broker-list 192.168.2.22:9092 --topic summer
			This is a messages
			welcome to kafka     
		(5)接收消息，这里使用的是消费者角色
			in/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
			[ root @ kafka2 ~ ] # /usr/share/kafka/bin/kafka-console-consumer.sh --bootstrap-server   192.168.2.24:2181 --topic summer --from-beginning
			This is a messages
			welcome to kafka
 			如果能够像上面一样能够接收到生产者发过来的消息，那说明基于kafka的zookeeper集群就成功啦。

	(1)修改webserver1上面的logstash配置，如下所示：各个参数可以到 官网 查询.
			root @ webserver1 etc ] # cat logstash.conf
			input {              #这里的输入还是定义的是从日志文件输入
			file {
			type = > "system-message"
			path = > "/var/log/messages"
			start_position = > "beginning"
			}
			}
			output {
			#stdout { codec => rubydebug }   #这是标准输出到终端，可以用于调试看有没有输出，注意输出的方向可以有多个
			kafka {    #输出到kafka
			bootstrap_servers = > "192.168.2.22:9092,192.168.2.23:9092,192.168.2.24:9092"   #他们就是生产者
			topic_id = > "system-messages"    #这个将作为主题的名称，将会自动创建
			compression_type = > "snappy"    #压缩类型
			}
			}
			[ root @ webserver1 etc ] #
	------------------------------elasticsearch --------------------
		vi /etc/elasticsearch/elasticsearch.yml
			network.host: 0.0.0.0

		systemctl start elasticsearch

	--------------------------------kabana---------------------------
		vi /etc/kabana/kibana.yml
			server.host: "0.0.0.0"
			systemctl start kibana
		
		systemctl start elasticsearch

	---------------------docker-------elk------------------------------
		docker run -d  -p 9200:9200  -v ~/elasticsearch/data:/usr/share/elasticsearch/data  --name elasticsearch elasticsearch
		docker run -d -p 4560:4560  -v ~/logstash.conf:/etc/logstash.conf  --link elasticsearch:elasticsearch  --name logstash logstash  logstash -f 
		/etc/logstash.conf
		docker run -d -p 5601:5601 --link elasticsearch:elasticsearch -e ELASTICSEARCH_URL=http://elasticsearch:9200 --name kibana kibana

30. ------redis--------------------------------------
	centos7 yum install redis
		直接yum 安装的redis 不是最新版本
			yum install -y epel-release
			yum install redis
			如果要安装最新的redis，需要安装Remi的软件源，官网地址：http://rpms.famillecollet.com/
			yum install -y http://rpms.famillecollet.com/enterprise/remi-release-7.rpm

			然后可以使用下面的命令安装最新版本的redis：
			yum --enablerepo=remi install redis
			安装完毕后，即可使用下面的命令启动redis服务
			service redis start
			或者
			systemctl start redis

			**   redis  设置密码
			vi /etc/redis.conf
			requirepass password123   -- 设置密码
			bind 127.0.0.1     -- 监听IP
			port  6379         -- 监听端口
			redis-cli  -h  127.0.0.1  -p  6379  -a  password123          ------ a  密码登陆


31. -----------pure-ftp -------------------------------------------
		pure-ftp
		yum install wget
		wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
		yum  install rpel-release 
		yum install pure-ftpd -y
		vi /etc/pure-ftpd/pure-ftpd.conf
			PureDB /etc/pure-ftpd/pureftpd.pdb   #  去掉注释
		useradd pure-ftp -s /sbin/nologin -M
		mkdir  -p  /data/ftp
		chown -R  pure-ftp:pure-ftp /data/ftp
		pure-pw useradd test1 -d /data/ftp/ -u pure-ftp  -m
		pure-pw useradd maket1 -u maket1  -d /comany/market/market1  -m （–m（把用户密码加入PDB数据库中，不需要重启FTP）
		pure-pw  userdel  
		pure-pw mkdb
		systemctl restart pure-ftpd

32. ---------------lvs ---------------------
	lvs
		echo 1 > /proc/sys/net/ipv4/ip_forward
		# 关闭icmp的重定向
		echo 0 > /proc/sys/net/ipv4/conf/all/send_redirects
		echo 0 > /proc/sys/net/ipv4/conf/default/send_redirects
		# 注意区分网卡名字，阿铭的两个网卡分别为ens33和ens37
		echo 0 > /proc/sys/net/ipv4/conf/ens33/send_redirects
		echo 0 > /proc/sys/net/ipv4/conf/ens37/send_redirects
		# director 设置nat防火墙
		iptables -t nat -F
		iptables -t nat -X

	lvs-NAT 模式:
		RS——SERVER :网关指向 调度器， 调度器双网卡。
		#! /bin/bash
		# director 服务器上开启路由转发功能
		echo 1 > /proc/sys/net/ipv4/ip_forward
		# 关闭icmp的重定向
		echo 0 > /proc/sys/net/ipv4/conf/all/send_redirects
		echo 0 > /proc/sys/net/ipv4/conf/default/send_redirects
		# 注意区分网卡名字，阿铭的两个网卡分别为ens33和ens37
		echo 0 > /proc/sys/net/ipv4/conf/ens33/send_redirects
		echo 0 > /proc/sys/net/ipv4/conf/ens37/send_redirects
		# director 设置nat防火墙
		iptables -t nat -F
		iptables -t nat -X
		iptables -t nat -A POSTROUTING -s 192.168.188.0/24  -j MASQUERADE
		# director设置ipvsadm
		IPVSADM='/usr/sbin/ipvsadm'
		$IPVSADM -C
		$IPVSADM -A -t 192.168.147.144:80 -s wlc -p 300
		$IPVSADM -a -t 192.168.147.144:80 -r 192.168.188.129:80 -m -w 1
		$IPVSADM -a -t 192.168.147.144:80 -r 192.168.188.127:80 -m -w 1

    lvs-DR模式
		1. 在dr 服务器上设置网卡第二地址
			ip address add 192.168.110.111/32 dev ens33:2
			ip  route add 192.168.110.111/32 dev ens33:2
		2. 设置ipvsadm
			ipvsadm -C
			ipvsadm -A -t 192.168.110.111:80 -s wrr
			ipvsadm -a -t 192.168.110.111:80 -r 192.168.110.85:80  -g -w 1
			ipvsadm -a -t 192.168.110.111:80 -r 192.168.110.86:80  -g -w 1
		3.  在rs 设置
			ip address add 192.168.110.111/32 dev lo:0
			ip  route add 192.168.110.111/32 dev lo:0
		4. 设置 arp 忽略
			echo "1" >/proc/sys/net/ipv4/conf/all/arp_ignore
			echo "2" >/proc/sys/net/ipv4/conf/all/arp_announce
		arp_ignore:
			定义对目标地址为本地IP的ARP询问不同的应答模式0
			0 - (默认值): 回应任何网络接口上对任何本地IP地址的arp查询请求
			1 - 只回答目标IP地址是来访网络接口本地地址的ARP查询请求
			2 -只回答目标IP地址是来访网络接口本地地址的ARP查询请求,且来访IP必须在该网络接口的子网段内
			3 - 不回应该网络界面的arp请求，而只对设置的唯一和连接地址做出回应
			4-7 - 保留未使用
			8 -不回应所有（本地地址）的arp查询 
			确定了向外发送ARP请求的发出地址 也即使VIP 地址
		arp_announce - INTEGER
			对网络接口上，本地IP地址的发出的，ARP回应，作出相应级别的限制:  
			确定不同程度的限制,宣布对来自本地源IP地址发出Arp请求的接口
			0 - (默认) 在任意网络接口（eth0,eth1，lo）上的任何本地地址
			1 -尽量避免不在该网络接口子网段的本地地址做出arp回应. 当发起ARP请求的源IP地址是被设置应该经由路由达到此网络接口的时候很有用.此时会检查来访IP是否为所有接口上的子网段内ip之一.如果改来访IP不属于各个网络接口上的子网段内,那么将采用级别2的方式来进行处理.
			2 - 对查询目标使用最适当的本地地址.在此模式下将忽略这个IP数据包的源地址并尝试选择与能与该地址通信的本地地址.首要是选择所有的网络接口的子网中外出访问子网中包含该目标IP地址的本地地址. 如果没有合适的地址被发现,将选择当前的发送网络接口或其他的有可能接受到该ARP回应的网络接口来进行发送. 
			限制了使用本地的vip地址作为优先的网络接口

		keepalive——lvs：  dr
			1.调度器安装 KEEPALIVED, IPVSADM
			2. real——server 执行 按 nginx，
			ip address add 192.168.110.111/32 dev lo:0
			ip  route add 192.168.110.111/32 dev lo:0
			echo "1" >/proc/sys/net/ipv4/conf/all/arp_ignore
			echo "2" >/proc/sys/net/ipv4/conf/all/arp_announce
	3. DR  的keepalived.cnf
			vrrp_instance VI_1 {
				#备用服务器上为 BACKUP
				state MASTER
				#绑定vip的网卡为ens33，你的网卡和阿铭的可能不一样，这里需要你改一下
				interface ens33
				virtual_router_id 51
				#备用服务器上为90
				priority 100
				advert_int 1
				authentication {
					auth_type PASS
					auth_pass aminglinux
				}
				virtual_ipaddress {
					192.168.188.110
				}
			}
			virtual_server 192.168.188.110 80 {
				#(每隔10秒查询realserver状态)
				delay_loop 10
				#(lvs 算法)
				lb_algo wlc
				#(DR模式)
				lb_kind DR
				#(同一IP的连接60秒内被分配到同一台realserver)
				persistence_timeout 60
				#(用TCP协议检查realserver状态)
				protocol TCP

				real_server 192.168.188.129 80 {
					#(权重)
					weight 100
					TCP_CHECK {
					#(10秒无响应超时)
					connect_timeout 10
					nb_get_retry 3
					delay_before_retry 3
					connect_port 80
					}
				}
				real_server 192.168.188.127 80 {
					weight 100
					TCP_CHECK {
					connect_timeout 10
					nb_get_retry 3
					delay_before_retry 3
					connect_port 80
					}
				 }
			}

	4.  backup 的keepalive  修改 keepalived.cnf 中：state BACKUP ,priority 100 

33.keepalived  1.3.5 --------------------------------------------
		yum  install  -y  epel-release
		yum install -y nginx keepalived
			vi /usr/sbin/check_nginx.sh
				#时间变量，用于记录日志
				d=`date --date today +%Y%m%d_%H:%M:%S`
				#计算nginx进程数量
				n=`ps -C nginx --no-heading|wc -l`
				#如果进程为0，则启动nginx，并且再次检测nginx进程数量，
				#如果还为0，说明nginx无法启动，此时需要关闭keepalived
				if [ $n -eq "0" ]; then
						systemctl start nginx
						n2=`ps -C nginx --no-heading|wc -l`
						if [ $n2 -eq "0"  ]; then
								echo "$d nginx down,keepalived will stop" >> /var/log/check_ng.log
								systemctl stop keepalived
						fi
				fi
	[root@centos85 sbin]# vi /etc/keepalived/keepalived.conf
			global_defs {
			notification_email {
				aming@aminglinux.com
			}
			notification_email_from root@aminglinux.com
			smtp_server 127.0.0.1
			smtp_connect_timeout 30
			router_id LVS_DEVEL
			}
			vrrp_script chk_nginx {
				script "/usr/sbin/check_nginx.sh"
				interval 3
			}
			vrrp_instance VI_1 {
				state BACKUP
				interface ens33
				virtual_router_id 51
				priority 90
				advert_int 1
				authentication {
					auth_type PASS
					auth_pass 1111
				}
				virtual_ipaddress {
					192.168.110.100
				}
				track_script {
					chk_nginx
				}
			}

24. mysql
		#创建mysql用户组
		#把用户mysql添加到mysql用户组， -r系统用户  -s /bin/nologin 用户不可登录 -M  不产生家目录
		# useradd -r -s /bin/nologin  -M  mysql
		# cd mysql
		# mkdir -p /data/mysql
		# chown  -R  mysql:mysql  /data/mysql
		#改变文件的所有权 -R表示改变一个目录和其下文件（或者子目录）的所有权设置 
		[root@localhost mysql]# chown -R mysql ./  #mysql下的所有目录和文件交给mysql用户
		[root@localhost mysql]# chgrp -R mysql ./  #mysql下的所有目录和文件交给mysql组

		wget http://repo.mysql.com/mysql57-community-release-el7-9.noarch.rpm
		rpm -vih mysql57-community-release-el7-9.noarch.rpm
		yum install mysql-community-server

		systemctl stop mysqld
		ln -s  /data/mysql/mysql.sock /var/lib/mysql/mysql.sock  #解决本地连接报 	ERROR 2002 错误
			或更改 /etc/my.cnf  , 添加如下内容：
			skip_grant_tables
			validate_password_policy=0
			validate_password_length=1
			[client]
			socket=/data/mysql/msyql.sock

		systemctl start mysqld
		change master to master_host='192.168.110.84',master_user='repl',master_password='pass',master_log_file='master-bin.000004',master_log_pos=159;

  		grep 'temporary password' /var/log/mysqld.log 
		cat /root/.mysql_secret # 查询密码
	更改密码： 
		mysqladmin -u root -p password  更改密码
			mysql -u root -p   
			mysql> 
				set global validate_password_policy=0;  #再修改密码的长度
				set global validate_password_length=1; #再次执行修改密码就可以了
				ALTER USER 'root'@'localhost' IDENTIFIED BY 'pass'; #（ALTER等可以写成小写）
				GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'pass' WITH GRANT OPTION;
				FLUSH  PRIVILEGES;

				set password for root@localhost = password(‘pass');

		 		show tables或show tables from database_name或show database_name.tables;
					解释：显示当前数据库中所有表的名称
				show databases; 解释：显示mysql中所有数据库的名称
				show processlist; 解释：显示系统中正在运行的所有进程，也就是当前正在执行的查询。大多数用户可以查看
					他们自己的进程，但是如果他们拥有process权限，就可以查看所有人的进程，包括密码。
				show table status; 解释：显示当前使用或者指定的database中的每个表的信息。信息包括表类型和表的最新更新时间
				show columns from table_name from database_name; 或show columns from database_name.table_name;或show fields;
					解释：显示表中列名称（和 desc table_name 命令的效果是一样的）
				show grants for user_name@localhost; 解释：显示一个用户的权限，显示结果类似于grant 命令
				show index from table_name;或show keys; 解释：显示表的索引
				show status; 解释：显示一些系统特定资源的信息，例如，正在运行的线程数量
				show variables; 解释：显示系统变量的名称和值
				show privileges; 解释：显示服务器所支持的不同权限
				show create database database_name; 解释：显示创建指定数据库的SQL语句
				show create table table_name; 解释：显示创建指定数据表的SQL语句
				show engies; 解释：显示安装以后可用的存储引擎和默认引擎。
				show innodb status; 解释：显示innoDB存储引擎的状态
				show logs; 解释：显示BDB存储引擎的日志
				show warnings; 解释：显示最后一个执行的语句所产生的错误、警告和通知
				show errors; 解释：只显示最后一个执行语句所产生的错误

				上面的大部分命令都可以用like，比如 show table like ‘%abce%’  
						show status 结果说明
						列 	含义
						Name 	表名
						Type 	表的类型 (ISAM，MyISAM或HEAP)
						Row_format 	行存储格式 (固定, 动态, 或压缩）
						Rows 	行数量
						Avg_row_length 	平均行长度
						Data_length 	数据文件的长度
						Max_data_length 	数据文件的最大长度
						Index_length 	索引文件的长度
						Data_free 	已分配但未使用了字节数
						Auto_increment 	下一个 autoincrement(自动加1）值
						Create_time 	表被创造的时间
						Update_time 	数据文件最后更新的时间
						Check_time 	最后对表运行一个检查的时间
						Create_options 	与CREATE TABLE一起使用的额外选项
						Comment 	当创造表时，使用的注释 (或为什么MySQL不能存取表信息的一些信息)。

				show index 结果说明：
						列 	含义
						Table 	表名
						Non_unique 	0，如果索引不能包含重复。
						Key_name 	索引名
						Seq_in_index 	索引中的列顺序号, 从 1 开始。
						Column_name 	列名。
						Collation 	列怎样在索引中被排序。在MySQL中，这可以有值A（升序) 或NULL（不排序)。
						Cardinality 	索引中唯一值的数量。这可通过运行isamchk -a更改.
						Sub_part 	如果列只是部分被索引，索引字符的数量。NULL，如果整个键被索引。

				show variables 结果说明：
						Aborted_clients 	由于客户没有正确关闭连接已经死掉，已经放弃的连接数量。
						Aborted_connects 	尝试已经失败的MySQL服务器的连接的次数。
						Connections 	试图连接MySQL服务器的次数。
						Created_tmp_tables 	当执行语句时，已经被创造了的隐含临时表的数量。
						Delayed_insert_threads 	正在使用的延迟插入处理器线程的数量。
						Delayed_writes 	用INSERT DELAYED写入的行数。
						Delayed_errors 	用INSERT DELAYED写入的发生某些错误(可能重复键值)的行数。
						Flush_commands 	执行FLUSH命令的次数。
						Handler_delete 	请求从一张表中删除行的次数。
						Handler_read_first 	请求读入表中第一行的次数。
						Handler_read_key 	请求数字基于键读行。
						Handler_read_next 	请求读入基于一个键的一行的次数。
						Handler_read_rnd 	请求读入基于一个固定位置的一行的次数。
						Handler_update 	请求更新表中一行的次数。
						Handler_write 	请求向表中插入一行的次数。
						Key_blocks_used 	用于关键字缓存的块的数量。
						Key_read_requests 	请求从缓存读入一个键值的次数。
						Key_reads 	从磁盘物理读入一个键值的次数。
						Key_write_requests 	请求将一个关键字块写入缓存次数。
						Key_writes 	将一个键值块物理写入磁盘的次数。
						Max_used_connections 	同时使用的连接的最大数目。
						Not_flushed_key_blocks 	在键缓存中已经改变但是还没被清空到磁盘上的键块。
						Not_flushed_delayed_rows 	在INSERT DELAY队列中等待写入的行的数量。
						Open_tables 	打开表的数量。
						Open_files 	打开文件的数量。
						Open_streams 	打开流的数量(主要用于日志记载）
						Opened_tables 	已经打开的表的数量。
						Questions 	发往服务器的查询的数量。
						Slow_queries 	要花超过long_query_time时间的查询数量。
						Threads_connected 	当前打开的连接的数量。
						Threads_running 	不在睡眠的线程数量。
						Uptime 	服务器工作了多少秒。
							关于上面的一些注释：
							如果Opened_tables太大，那么你的table_cache变量可能太小。
							如果key_reads太大，那么你的key_cache可能太小。缓存命中率可以用key_reads/key_read_requests计算。
							如果Handler_read_rnd太大，那么你很可能有大量的查询需要MySQL扫描整个表或你有没正确使用键值的联结(join)。

	--------------------------------mysql----------主从复制------------------------------------------------------------
			mysql  主从复制：
			master 配置：
			vi  my.cnf
				[mysqld]
				log-bin=mysql-bin
				server-id=1
				innodb-file-per-table =ON
				replicate-do-db=db,db2
				replicate-ignore-db=db3

			systemctl  start mysqld
			mysql > grant replication slave on *.* to 'rep'@‘%’ identified by 'pass';  -建复制账户
					flush privileges;
					flush table with read lock;
			备份主数据库sqldump
					show master status ;
					unlock tables;
			slave 配置：
				vi my.cnf
						[mysqld]
						server-id=2
						relay-log=mysql-relay
						relay-log-index=relay-log.index
						innodb-file-per-table =ON
						replicate-do-db=db,db2
						replicate-ignore-db=db3
						read_only=1
			mysql -u root -p -e "show global  variables like '%log%'"
				1：限制从服务器为只读
				在从服务器上设置：
				read_only = ON,但是此限制对拥有SUPER权限 的用户均无效。
				阻止所有用户：
				mysq>FLUSH TABLES WITH READ LOCK;
					stop slave;
					change master to master_host='192.168.110.85',master_user='repl',master_password='pass',master_log_file='master.000002',master_log_pos=159;
					start slave;
					show slave status;
					start slave ;
					start slave IO_THREAD;

	-----------------------------mariadb ------------------------
	mariadb：
		yum install mariadb-server -y
		mkdir -p /data/mysql
		chown -R  mysql:mysql /data/mysql
		mysql_install_db  --datadir=/data/mysql
		systemctl enable mariadb
		systemctl start mariadb
		mysqladmin -u root password pass  # 设置msyql  root 密码
		mysql -u root -p   #登陆mysql
		/usr/share/mysql/*.cnf  #标准配置文件  多个
		cp /usr/share/mysql/my-small.cnf  /etc/my.cnf
		vi /etc/my.cnf    # mysql 配置文件
			/etc/my.cnf.d/*    # server 配置文件
			datadir=
			stock=
	2、配置MariaDB的字符集
		vi /etc/my.cnf 添加
			[mysqld]
			init_connect='SET collation_connection = utf8_general_ci' 
			init_connect='SET NAMES utf8' 
			character-set-server=utf8 
			collation-server=utf8_general_ci 
			skip-character-set-client-handshake

		vi /etc/my.cnf.d/client.cnf 在[client]中添加
			default-character-set=utf8
			vi /etc/my.cnf.d/mysql-clients.cnf
			在[mysql]中添加
			default-character-set=utf8
			全部配置完成，
		重启mariadb
		systemctl restart mariadb 
		MariaDB查看字符集
			mysql> show variables like "%character%";show variables like "%collation%";
			显示为

			+--------------------------+----------------------------+
			| Variable_name            | Value                      |
			+--------------------------+----------------------------+
			| character_set_client    | utf8                      |
			| character_set_connection | utf8                      |
			| character_set_database  | utf8                      |
			| character_set_filesystem | binary                    |
			| character_set_results    | utf8                      |
			| character_set_server    | utf8                      |
			| character_set_system    | utf8                      |
			| character_sets_dir      | /usr/share/mysql/charsets/ |
			+--------------------------+----------------------------+
			8 rows in set (0.00 sec)

			+----------------------+-----------------+
			| Variable_name        | Value          |
			+----------------------+-----------------+
			| collation_connection | utf8_unicode_ci |
			| collation_database  | utf8_unicode_ci |
			| collation_server    | utf8_unicode_ci |
			+----------------------+-----------------+
			3 rows in set (0.00 sec)

		字符集配置完成。
	3、添加用户，设置权限
		创建用户命令
			mysql>create user username@localhost identified by 'password'; 直接创建用户并授权的命令
			mysql>grant all on *.* to username@localhost indentified by 'password'; 授予外网登陆权限 
			mysql>grant all privileges on *.* to username@'%' identified by 'password'; 授予权限并且可以授权
			mysql>grant all privileges on *.* to username@'hostname' identified by 'password' with grant option;

		开启和停用Binlog
		通过配置/etc/my.cnf配置文件的log-bin选项：
			[mysqld]
			log-bin=mysql-bin
			binlog_format='ROW'          #放在mysqld模块下面
			or
			log_bin=ON
			log_bin_basename=/var/lib/mysql/mysql-bin
			log_bin_index=/var/lib/mysql/mysql-bin.index

	4、	mysqlbinlog：
		show variables like ‘%log_bin%’  
		mysql> SHOW BINARY LOGS;
			set global binlog_format='ROW';　　
			show master status 可以查看binlog的状态
			reset master 清空binlog日志文件
			flush logs; - .通过flush logs 可以手动刷新日志，生成一个新的binlog文件

	在使用二进制日志文件进行数据库恢复时，该过程中也会产生日志文件，就会进入一个循环状态，继续恢复该过程中的数据。因此，当使用mysqlbinlog命令时，要禁用二进制日志，请使用下面所示的-D选项： 
		mysqlbinlog -D mysqld-bin.000001  禁止恢复过程产生日志
		mysqlbinlog --disable-log-bin mysqld-bin.000001  禁止恢复过程产生日志
		mysqlbinlog -database crm mysqld-bin.000001 > crm-events.txt
		mysqlbinlog -s mysqld-bin.000001   仅显示sql语句  --short-form
		mysqlbinlog mysqld-bin.000001 > output.out
		mysqlbinlog -j 15028 mysqld-bin.000001 > from-15028.out  从位置编号为15028的二进制日志条目处开始读取
		mysqlbinlog --start-datetime="2017-08-16 10:00:00" mysqld-bin.000001
			当你想要从一个二进制文件中提取数据时，这是非常有用的，因为你希望使用它来恢复或重构在某个时间段内发生的某些数据库活动。时间戳的格式可以是MySQL服务器所理解的DATETIME和timestamp中的任何类型。
		mysqlbinlog --stop-datetime="2017-08-16 15:00:00" mysqld-bin.000001 命令将读取到给定结束时间的条目
		mysqlbinlog --stop-position=15028 mysqld-bin.000001 > upto-15028.out 就像前面的例子一样，你也可以从mysql二进制日志中截止到一个特定位置的条目
		#mysqlbinlog --base64-output="decode-rows" -v mysql-bin.000001  Row模式下解析binlog日志
		
======================  msyql8.0  ==========================

		MSYQL 8.0 安装指导 https://dev.mysql.com/doc/refman/8.0/en/binary-installation.html
	YUM 安装
		https://dev.mysql.com/doc/refman/8.0/en/linux-installation-yum-repo.html
		wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm
		yum localinstall mysql80-community-release-el8-{version-number}.noarch.rpm
		yum localinstall mysql80-community-release-el7-3.noarch.rpm
		yum repolist enabled | grep "mysql.*-community.*"
		yum repolist all | grep mysql
		yum  install mysql-community-server -y
		
		mkdir -p /data/mysql
		mkdir -p /var/lib/mysql
		groupadd mysql
		useradd mysql
		chown -R mysql.mysql /data/mysql
		chown -R mysql.mysql /var/lib/mysql
		vi  /etc/my.cnf
			datadir=/data/mysql
			socket=/var/lib/mysql
		
            default-authentication-plugin=mysql_native_password  #使用旧认·证
			default_authentication_plugin=caching_sha2_password  #使新认证
	
	-----------------------------------------------------	
	/etc/my.cnf  #推荐配置
		[mysqld]
		datadir=/data/mysql
		basedir=/usr/local/mysql
		socket=/tmp/mysql.sock
		pid-file=/tmp/mysqld.pid
		# Disabling symbolic-links is recommended to prevent assorted security risks

		symbolic-links=0

		# Settings user and group are ignored when systemd is used.
		# If you need to run mysqld under a different user or group,
		# customize your systemd unit file for mariadb according to the
		# instructions in http://fedoraproject.org/wiki/Systemd

		#server-id                      = 1
		port                           = 3306
		
		default-authentication-plugin=mysql_native_password   #使用

		log-error                      = error.log
		slow-query-log                 = 1

		slow-query-log-file            = slow.log
		long_query_time                = 0.2
		log-bin                        = bin.log
		binlog_format                 =ROW
		character-set-client-handshake = FALSE
		character-set-server           = utf8mb4
		collation-server               = utf8mb4_unicode_ci
		init_connect                   ='SET NAMES utf8mb4'
		innodb_buffer_pool_size        = 200M
		join_buffer_size               = 10M
		sort_buffer_size               = 2M
		read_rnd_buffer_size           = 2M
		log_timestamps                 = SYSTEM
		[mysqld_safe]
		log-error=/var/log/mysqldb.log
		#
		# include all files from the config directory
		#
		!includedir /etc/my.cnf.d
	-------------------------------------------------
	
		systemctl start mysqld
		systemctl enable  mysqld
	    cat /var/log/mysqld.log |grep password
	    mysqladmin  -u root -p password   # 更改密码
	    mysql -u root -p    #登陆mysql
		   create user root@'%' identified by 'pass';
		   alter user  root@'%' identified with mysql_native_password by 'pass';  #设置native 密码
		   grant all privileges on *.* to root@'%';   #设置权限
		   flush privileges;
		   \q                        #退出
	
	tar 安装：
		tar  xvf mysql-8.0.23-linux-glibc2.12-x86_64.tar.xz
		mv mysql-8.0.23-linux-glibc2.12-x86_64/ /usr/local
		ln -vs /usr/local/mysql-8.0.23-linux-glibc2.12-x86_64/ /usr/local/mysql
		
		useradd  -r  -M -s /bin/nologin   mysql
		mdir -p  /data/mysql
		echo 'export PATH=$PATH:/usr/local/mysql/bin' >> /etc/profile
		source   /etc/profile
		vi /etc/my.cnf
			[mysqld]
			user=mysql
			basedir=/usr/local/mysql
			datadir=/data/mysql
			pid-file=/data/mysql/mysqldb.pid
			log-error=/var/log/mysql.log
			#socket=/var/lib/mysql/mysql.sock
			#validate_password.policy=0  #密码策略low
			#validate_password.check_user_name=off
			#validate_password.length=0  #密码长度
			default-authentication-plugin=mysql_native_password
			[mysqld_safe]
			!includedir /etc/my.cnf.d

		mysqld --initialzize-insecure   #安装 密码为空
		mysqld  --initiazlize      #安装 自动生成密码
		cp /usr/local/mysql/support-files/mysql.server  /etc/init.d/

		chkconfig -add  mysql.server     #设置服务
		systemctl   start  mysql         #启动mysql
		cat  /var/log/mysql.log  |grep  password    # 查看密码
		mysqladmin  -u root  -p password            # 更改密码
		
	SQL  主从复制
				/etc/my.cnf
					[mysqld]
					log-bin=mysql-bin
					server-id=39             # 必须唯一， 主和从不能相同
					relay-log-index=slave-relay-bin.index
					relay-log=slave-relay-bin
					#binlog-do-db=palan-dev    #待同步的数据库
					#binlog-ignore-db=mysql  #不同步的数据 
					#expire_logs_days=7      #设置log文件保留天数
			在master 执行：
				show  master  status\G;
				查看binlog文件 及pos 位置
				新建复制用户并授权
				create user mysync@'%' identified by 'pass';
				grant replication slave on *.* to mysync@'%';
				flush privileges;
			在slave上执行
				CHANGE MASTER TO 
					MASTER_HOST='centos37',
					MASTER_USER='mysync',
					MASTER_PASSWORD='pass',
					MASTER_PORT=3306,
					MASTER_LOG_FILE='binlog.000001',
					MASTER_LOG_POS=1,
					MASTER_CONNECT_RETRY=10;
			start slave；
			show slave status\G;
			查看：
				Slave_IO_Running: Yes
				Slave_SQL_Running: Yes

	binlong
		show master logs  #查看log 信息
		flush  logs       # 生成新的log文件
		reset  master     # 清除所有binlog 文件
		show variables like 'binlog_format';   # 查看binlog 格式
							ROW    # 行 只记录更新，无上文
							STATMENT   # 语句模式
							MIXED  #混合模式
		查看binlog
			show binlog events [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count]
			Event_type
				QUERY_ EVENT 与数据无关的操作，begin、drop table、truncate table等
				TABLE MAP EVENT 记录下一个操作所对应的表信息，存储了数据库名和表名
				XID_ EVENT 标记事务提交
				WRITE ROWS EVENT 插入数据,即insert操作
				UPDATE ROWS EVENT 更新数据,即update操作
				DELETE ROWS EVENT 删除数据,即delete操作
		show binlog events in 'binlog.000001' from 417 limit 1, 2;  #例子
	mysqlbinlog
			mysqlbinlog  --base64-output=decode-rows -v binlog.000001 > kk.sql  #查看binlog 并生成sql 
			mysqlbinlog binlog.000001 --start-position=200  --stop-position=300 | mysql -u root -p   # 还原部分数据到数据库
			mysqlbinlog node1_bin.000001 |mysql -uroot -p   # 将binlog 还原到数据库中
			mysqlbinlog node1_bin.000001 --start-datetime='2018-07-23 14:00:00' --stop-datetime='2018-07-23 16:10:00' --database=wuhan 
			mysqlbinlog node1_bin.000001 --start-datetime='2018-07-23 14:00:00' --stop-datetime='2018-07-23 16:10:00' --database=wuhan  --set-charset=utf8 #可转换字符集
			mysqlbinlog  --read-from-remote-server --host=172.16.1.79 --user=repl --password=repl --port=3311 node1_bin.000001 | more #查看远程主机的binlog 需要有replaction slave  权限
			mysqlbinlog --short-form node1_bin.000001 # 查看短格式log
			mysqlbinlog --offset=10 node1_bin.000001  # 调过N条
			mysqlbinlog -o 10 node1_bin.000001  # 调过N条 

	binlog  保留时间设置
			show variables like 'expire_log%';  #临时设置
			flush logs      #滚动第一个日志
		/etc/my.cnf 
			expire_logs_days = 7     #永久设置 保留7天
		
	mysql 备份
	    备份前需要运行：
		     flush tables with read lock;    # 施加锁，表示把位于内存上的表统统都同步到磁盘上去
			 unlock tables；  #解锁
	 
		mysqldump -h 192.168.0.76 -p -P 6033  --all-databases > /data/pzdbbak.db
		mysqldump -uroot  -p --single-transaction --master-data=2 --databases hellodb > /backup/hellodb_`date +%F`.sql
			--single-transaction: 基于此选项能实现热备InnoDB表；因此，不需要同时使用--lock-all-tables；
			--master-data=2  记录备份那一时刻的二进制日志的位置，并且注释掉，1是不注释的
			--databases hellodb 指定备份的数据库
			
	查看备份的position
		数据库还原前处理
			mysql>  set  sql_log_bin =0   # 关闭binlog记录
					flush logs            #生成新的log日志文件
					source  /root/db_backup.db   #还原数据库
					source  /root/db_backup_inc.sql  # 还原增量备份
					set  sql_log_bin =1  # 开启binlog记录
			mysqlbinlog --start-position=15694 --stop-position=15982  \              #增量备份
					/mydata/data/mysql-bin.000013 > /backup/hellodb_`date +$F_%H`.sql

	查看数据库字符集和字符序
		use test_schema; 
		SELECT @@character_set_database, @@collation_database; 

		character_set_client      为客户端编码方式；
		character_set_connection  为建立连接使用的编码；
		character_set_database    为数据库的编码；
		character_set_results     为结果集的编码；
		character_set_server      为数据库服务器的编码；
	新建数据库	
		CREATE DATABASE IF NOT EXISTS test_db_char 
		-> DEFAULT CHARACTER SET utf8
		-> DEFAULT COLLATE utf8_general_ci;
	#创建临时表
	DROP TABLE IF EXISTS `wl_ognid_lasteday`;
    create temporary table  wl_ognid_lasteday select ..  from ...

	xtrabackup
		https://www.percona.com/doc/percona-xtrabackup/8.0/index.html#user-s-manual #使用手册
		wget https://repo.percona.com/yum/release/7/RPMS/x86_64/qpress-11-1.el7.x86_64.rpm
		yum  localinstall    qpress.rpm
		全量备份并压缩
		xtrabackup  --defaults-file=/etc/my.cnf  --host=192.168.110.39 --user=root --password=pass --socket=/tmp/mysql.sock   --port=3306  --backup --compress  --target-dir=/root/trabak
		xtrabackup --user=root --password=123456 --defaults-file=/etc/my.cnf --database=zztx --stream=tar /data/back_data/ 2>/data/back_data/zztx.log | gzip     1>/data/back_data/zztx.tar.gz
			--database=zztx 单独对zztx数据库做备份 ，若是不添加此参数那就那就是对全库做备份
      		2>/data/back_data/zztx.log  输出信息写入日志中
      		1>/data/back_data/zztx.tar.gz 打包压缩存储到该文件中
		xtrabbackup  --decompress  --target-dir=/root/traback  #解压缩
		xtrabackup --decompress --remove-original --target-dir=/root/trabak_p1  #解压并删除原压缩文件
		xtrabackup  --prepare   --target-dir=/root/traback  
		xtrabackup   --host=192.168.110.39 --user=root --password=pass   --port=3306  --datadir=/data1  --copy-back  --target-dir=/root/trabak  # 全量还原
		增量备份：
		xtrabackup --defaults-file=/etc/my.cnf --host=172.16.1.52 --user=root --password=xxxyyy --port=3310 --backup --parallel=3 --target-dir=/data/backup/
		xtrabackup --defaults-file=/etc/my.cnf --host=172.16.1.52 --user=root --password=xxxyyy --port=3310 --backup --parallel=3 --target-dir=/data/backupIncr  --incremental-basedir=/data/backup
		增量还原：
		systemctl  stop mysql  #停数据库
        xtrabackup --prepare --apply-log-only --target-dir=/data/backup
		xtrabackup --prepare --apply-log-only --target-dir=/data/backup  --incremental-dir=/data/backupIncr
		xtrabackup --host=172.16.1.52 --user=root --password=xxxyyy --port=3310 --datadir=/data/crm --copy-back --target-dir=/data/backup/
 
	查询数据库空间（M 兆）
			select sum((data_length+index_length)/1024/1024) m from information_schema.tables where table_schema="dbname";
			select table_schema, sum((data_length+index_length)/1024/1024) M from information_schema.tables where table_schema is not null group by table_schema;
			select * from students where Age > 30 into outfile ‘/tmp/stud.txt' ;  #导出文件
				mysql> load data infile '/tmp/stud.txt' into table students;   #导入文件
		查询
				show grants for 'root'@'localhost';      #查询用户权限
				show variables like '%max_connections%';   #查询最大连接数
		查询连接数
			show status like 'Threads%';
				Threads_cached : 代表当前此时此刻线程缓存中有多少空闲线程。
				Threads_connected :代表当前已建立连接的数量，因为一个连接就需要一个线程，所以也可以看成当前被使用的线程数。
				Threads_created :代表从最近一次服务启动，已创建线程的数量。
				Threads_running :代表当前激活的（非睡眠状态）线程数。并不是代表正在使用的线程数，有时候连接已建立，但是连接处于sleep状态，这里相对应的线程也是sleep状态。
mysq  查询状态：
		show full processlist   # 查询进程状态
		show status            # 查询sql 状态
		check  table  [tables]  #检查表
		repair  table  [talbe]  #修复表
        optimize table [table]  #优化表

		mysqladmin -uroot -p  -h  192.168.1.11 status   #查询状态
		mysqlcheck  -u root -p  -c --database DB1   #检查数据库
		                       	A, –all-databases 表示所有库
								-a, –analyze 分析表
								-o, –optimize 优化表
								-r, –repair 修复表错误
								-c, –check 检查表是否出错
								–auto-repair 自动修复损坏的表
								-B, –databases 选择多个库
								–auto-repair  自动修复
		mysqlcheck -c DB1 table  -uroot -p  #检查指定数据库的表
		



ceph:
		curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
		curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
		
		wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
		wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
		yum  install epel-release  wget  vim   ntpdate   lrzsz  bash-completion net-tools zip unzip bzip2 lsof iptables -y ipcutils
		
		wget https://mirrors.aliyun.com/ceph/rpm-mimic/el7/noarch/ceph-release-1-1.el7.noarch.rpm
		yum localinstall  ceph-release-1-1.el7.noarch.rpm -y
		yum  clean all
		yum  makecache
		
		       
		yum  update		
		timedatectl set-timezone Asia/Shanghai
		ntpdate time1.aliyun.com
		echo "00 */1 * * * root /usr/sbin/ntpdate time1.aliyun.com;hwclock -w" >> /etc/crontab
		
		yum install ceph-deploy python-setuptools  python2-subprocess32 -y
		
		useradd  cephadmin
		passwd cephadmin
		/etc/sudoers.d/cephadmin 
		   cephadmin  ALL=(root)  NOPASSWD: ALL
		scp   /etc/sudoers.d/cephadmin   root@centos52:/etc/sudoers.d/
		
		su -cephadmin
		ssh-keygen -t rsa  -P  ''
		ssh_copy_id   cephadmin@centos52
		
		cd ~  （/home/cephadmin)
		mkdir   ceph-cluster
		ceph-deploy  install centos52 centos53 centos54 centos55
		or:
		yum  install ceph  ceph-redosgw  -y   ( centos 52-55  yum install )
		
		centos51:
		yum  install ceph-common   （admin  安装 client命令）
		
		cephadmin 用户下：
		cd /home/cephadmin/ceph-cluster
		ceph-deploy new --cluster-network 192.168.110.0/24 --public-network 192.168.120.0/24  centos52
		
		ceph-deploy  install  --no-adjust-repos  centos52 centos52 centos54 centos55
				
		ceph-deploy mon create-initial
		ceph-deploy admin  centos51 centos52 centos53 centos54 centos55  (copy  key and config to client)
		
		sudo setfacl -m u:cephadmin:rw /etc/ceph/ceph.client.admin.keyring  (每个client要设置权限）
		ceph-deploy mon  add   centos54
	    ceph-deploy mgr create  centos54
		ceph-deploy mgr create centos53
		
		ceph -status   (查看状态）
		
		ceph-deploy disk  list  centos51 centos52 centos53  centos54 centos55
		ceph-deploy disk zip centos52 /dev/sdb
		ceph-deploy disk zip centos52 /dev/sdc
		
		ceph-deploy osd create --data  /dev/sdb  centos52
		ceph-deploy osd create --data  /dev/sdc  centos52
		
		ceph-deploy  
		ceph-deploy mon add  centos53 centos54
		
		
		ceph  osd  pool  create  mypool  32 32 
		ceph  osd pool ls
		ceph  osd lspools  查看pool 池
		ceph quorum_status --f json-pretty  （查看成员状态）
		
		ceph  osd  map mypool   xxxx
		ceph os  rm pool  mypool  mypool --yes-i-really-really-mean-it
        ceph quorum_status -f json-pretty  (查看状态）
		ceph osd pool get mypool size  （查看副本数量）
        ceph health detail
		ceph osd pool  applicatin  eanble mypool
        ceph osd pool application enable mypool1 mypool1  --yes-i-really-mean-it rbc    (对pool 进行应用分类）

		
		
		
		rados  put   xxx  /etc/xxx  -p mypool
		rados ls -p  mypool
		rados  get  xxx  /xxx   -p  mypool
		rados  rm  xxx -p  mypool
		
		rbd create -p mypool  --image  imageaaaa.img --sieze  5G  
		rbd -p mypool ls 
		rbd -p mypool ls -l
		rbd -p  mypool  info  imageaaaa.imge
		rbd resize -p mypool --image imagdx.img  -s 6G   （更改大小）
		rbd  rm -p  mypool   imagexx.img

	
		rbd showmapped

		
		
    	 rbd -p mypool --image imagdx.img feature disable deep-flatten
		 rbd -p mypool --image imagdx.img feature disable fast-diff
		 rbd -p mypool --image imagdx.img feature disable object-map
		 rbd -p mypool --image imagdx.img feature disable exclusive-lock

         rbd map  -p mypool  --image  imagdx.img
         rbd showmapped
         rbd unmap  /dev/rbd0
         ceph osd pool application enable mypool mypool  --yes-i-really-mean-it
 
        resize2fs    (扩容文件系统）
		 
		
		
		
		

		
		
		
		
		
		
		
		
		ceph-deploy  install  
